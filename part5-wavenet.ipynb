{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implimentation of a language model from the following research paper:\n",
    "# https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open(\"names.txt\", 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "VOCAB_SIZE = len(stoi.keys())\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "BLOCK_SIZE = 3  # Context length.  How many letters do we take to predict the next.\n",
    "\n",
    "# Build a data set.\n",
    "def build_dataset(words): \n",
    "    \"\"\"Build a data set from the given data.\n",
    "  \n",
    "    Returns: \n",
    "      torch.tensor: X inputs (context block_size long)\n",
    "      torch.tensor: Y labels\n",
    "    \"\"\"\n",
    "    X, Y = [], []\n",
    "  \n",
    "    for w in words:\n",
    "        context = [0] * BLOCK_SIZE\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix] # crop and append\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "# Going to split the training set.\n",
    "n1 = int(0.8*len(words))  # 80% for training.\n",
    "n2 = int(0.9*len(words))  # 10% for dev, and then 10% for eval.\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy-paste of the data types we build previously.\n",
    "\n",
    "# The classes we create here are the same API as nn.Module in PyTorch\n",
    "class Linear:\n",
    "  \n",
    "    def __init__(self, fan_in, fan_out, bias=True):\n",
    "        self.weight = torch.randn((fan_in, fan_out), generator=g) / fan_in**0.5\n",
    "        self.bias = torch.zeros(fan_out) if bias else None\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.out = x @ self.weight\n",
    "        if self.bias is not None:\n",
    "            self.out += self.bias\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "\n",
    "class BatchNorm1d:\n",
    "  \n",
    "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.training = True\n",
    "        # parameters (trained with backprop)\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta  = torch.zeros(dim)\n",
    "        # buffers (trained with a running 'momentum update')\n",
    "        self.running_mean = torch.zeros(dim)\n",
    "        self.running_var = torch.ones(dim)\n",
    "  \n",
    "    def __call__(self, x):\n",
    "        # calculate the forward pass\n",
    "        if self.training:\n",
    "            xmean = x.mean(0, keepdim=True) # batch mean\n",
    "            xvar  = x.var( 0, keepdim=True) # batch variance\n",
    "        else:\n",
    "            xmean = self.running_mean\n",
    "            xvar = self.running_var\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "        # update the buffers\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
    "                self.running_var  = (1 - self.momentum) * self.running_var  + self.momentum * xvar\n",
    "        return self.out\n",
    "  \n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]\n",
    "\n",
    "class Tanh:\n",
    "    def __call__(self, x):\n",
    "        self.out = torch.tanh(x)\n",
    "        return self.out\n",
    "    def parameters(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params:  47024\n"
     ]
    }
   ],
   "source": [
    "# Build the network\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "EMBED_SIZE = 10\n",
    "NUM_HIDDEN_NEURONS = 100\n",
    "L1_INPUT_SIZE = EMBED_SIZE * BLOCK_SIZE\n",
    "\n",
    "C = torch.randn((VOCAB_SIZE, EMBED_SIZE),            generator=g)\n",
    "layers = [\n",
    "    # Layer 1: Input from embeddings.\n",
    "    Linear(L1_INPUT_SIZE, NUM_HIDDEN_NEURONS, bias=False),\n",
    "    BatchNorm1d(NUM_HIDDEN_NEURONS),\n",
    "    Tanh(),\n",
    "    # Layer 2\n",
    "    Linear(NUM_HIDDEN_NEURONS, NUM_HIDDEN_NEURONS, bias=False),\n",
    "    BatchNorm1d(NUM_HIDDEN_NEURONS),\n",
    "    Tanh(),\n",
    "    # Layer 3\n",
    "    Linear(NUM_HIDDEN_NEURONS, NUM_HIDDEN_NEURONS, bias=False),\n",
    "    BatchNorm1d(NUM_HIDDEN_NEURONS),\n",
    "    Tanh(),\n",
    "    # Layer 4\n",
    "    Linear(NUM_HIDDEN_NEURONS, NUM_HIDDEN_NEURONS, bias=False),\n",
    "    BatchNorm1d(NUM_HIDDEN_NEURONS),\n",
    "    Tanh(),\n",
    "    # Layer 5\n",
    "    Linear(NUM_HIDDEN_NEURONS, NUM_HIDDEN_NEURONS, bias=False),\n",
    "    BatchNorm1d(NUM_HIDDEN_NEURONS),\n",
    "    Tanh(),\n",
    "    # Output layer\n",
    "    Linear(NUM_HIDDEN_NEURONS, VOCAB_SIZE, bias=False),\n",
    "    BatchNorm1d(VOCAB_SIZE),\n",
    "]\n",
    "with torch.no_grad():\n",
    "  # last layer: make less confident\n",
    "  layers[-1].gamma *= 0.1\n",
    "\n",
    "parameters = [C] + [p for layer in layers for p in layer.parameters()]\n",
    "print(\"Total params: \", sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/  20000: 3.2870\n",
      "   1000/  20000: 2.2807\n",
      "   2000/  20000: 2.6592\n",
      "   3000/  20000: 2.4179\n",
      "   4000/  20000: 2.0728\n",
      "   5000/  20000: 1.9455\n",
      "   6000/  20000: 2.1830\n",
      "   7000/  20000: 2.2762\n",
      "   8000/  20000: 2.2768\n",
      "   9000/  20000: 2.2899\n",
      "  10000/  20000: 2.3273\n",
      "  11000/  20000: 2.4599\n",
      "  12000/  20000: 2.5290\n",
      "  13000/  20000: 1.8646\n",
      "  14000/  20000: 2.6447\n",
      "  15000/  20000: 2.0133\n",
      "  16000/  20000: 1.9743\n",
      "  17000/  20000: 2.4100\n",
      "  18000/  20000: 2.2002\n",
      "  19000/  20000: 2.4772\n",
      "2.0607450008392334\n"
     ]
    }
   ],
   "source": [
    "max_steps = 20000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "ud = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors\n",
    "    x = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "    for layer in layers:\n",
    "        x = layer(x)\n",
    "    loss = F.cross_entropy(x, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for layer in layers:\n",
    "        layer.out.retain_grad() # AFTER_DEBUG: would take out retain_graph\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 15000 else 0.01 # step learning rate decay\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "\n",
    "    # track stats\n",
    "    if i % 1000 == 0: # print every once in a while\n",
    "        print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.item())\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.1310999393463135\n",
      "val 2.152378797531128\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "    \"\"\"Simple function to take a split of the data and compute the loss.  No\n",
    "    gradients will be calculated.\"\"\"\n",
    "    x,y = {\n",
    "        'train': (Xtr,  Ytr),\n",
    "        'val'  : (Xdev, Ydev),\n",
    "        'test' : (Xte,  Yte),\n",
    "    }[split]\n",
    "    # forward pass\n",
    "    emb = C[x] # embed the characters into vectors\n",
    "    x = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "    for layer in layers:\n",
    "        x = layer(x)\n",
    "    loss = F.cross_entropy(x, y) # loss function\n",
    "    print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb00083dc40>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb0106538e0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(torch.tensor(lossi).view(-1, 500).mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carmah.\n",
      "amelle.\n",
      "khi.\n",
      "mili.\n",
      "taty.\n",
      "skaassie.\n",
      "mahnel.\n",
      "deliah.\n",
      "jareen.\n",
      "nellara.\n",
      "chaiiv.\n",
      "kaleigh.\n",
      "ham.\n",
      "join.\n",
      "quinn.\n",
      "shon.\n",
      "malianni.\n",
      "watthoniearyxi.\n",
      "jace.\n",
      "pilra.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for layer in layers:\n",
    "   layer.training = False\n",
    "\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * BLOCK_SIZE # initialize with all ...\n",
    "    while True:\n",
    "      # forward pass the neural net\n",
    "      emb = C[torch.tensor([context])] # (1,block_size,n_embd)\n",
    "      x = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "      for layer in layers:\n",
    "        x = layer(x)\n",
    "      logits = x\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      # sample from the distribution\n",
    "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "      # shift the context window and track the samples\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      # if we sample the special '.' token, break\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out)) # decode and print the generated word"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We currently have too many steps in our forward pass.  The embedding step is outside of our layers, and the flattening after getting the embeddings is a separate step.  We need to make special types to perform those functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will name the classes the same way they are named in torch.\n",
    "class Embedding:\n",
    "    def __init__(self, num_embeddings, embedding_dimensions):\n",
    "        \"\"\"Inputs:\n",
    "            num_embeddings:       Normally the total vocab size.\n",
    "            embedding_dimensions: The size of the embedding dimensional space.\n",
    "        \"\"\"\n",
    "        self.weight = torch.randn((num_embeddings, embedding_dimensions))\n",
    "    \n",
    "    def __call__(self, IX):\n",
    "        self.out = self.weight[IX]  # Perform the embedding, ie fetch the embedding vector for every input.\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.weight]\n",
    "\n",
    "class Flatten:\n",
    "    def __call__(self, x):\n",
    "        \"\"\"Keep the first dimention, and let torch figure out how to arrange all the other\n",
    "        dimensions to make a 2-D matrix.\n",
    "        \"\"\"\n",
    "        self.out = x.view(x.shape[0], -1)\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "class Sequential:\n",
    "    \"\"\"Class to hold a list of layers that should be called in sequence.\"\"\"\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        self.out = x\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params:  47024\n"
     ]
    }
   ],
   "source": [
    "# We can rebuild the network as pure layers.\n",
    "g = torch.Generator().manual_seed(42) # for reproducibility\n",
    "EMBED_SIZE = 10\n",
    "NUM_HIDDEN_NEURONS = 100\n",
    "L1_INPUT_SIZE = EMBED_SIZE * BLOCK_SIZE\n",
    "\n",
    "model = Sequential([\n",
    "    # Layer 0: Embeddings.\n",
    "    Embedding(VOCAB_SIZE, EMBED_SIZE),\n",
    "    # Layer 0b: Flatten to an input to the hidden layers.\n",
    "    Flatten(),\n",
    "    # Layer 1: Input from embeddings.\n",
    "    Linear(L1_INPUT_SIZE, NUM_HIDDEN_NEURONS, bias=False),\n",
    "    BatchNorm1d(NUM_HIDDEN_NEURONS),\n",
    "    Tanh(),\n",
    "    # Layer 2\n",
    "    Linear(NUM_HIDDEN_NEURONS, NUM_HIDDEN_NEURONS, bias=False),\n",
    "    BatchNorm1d(NUM_HIDDEN_NEURONS),\n",
    "    Tanh(),\n",
    "    # Layer 3\n",
    "    Linear(NUM_HIDDEN_NEURONS, NUM_HIDDEN_NEURONS, bias=False),\n",
    "    BatchNorm1d(NUM_HIDDEN_NEURONS),\n",
    "    Tanh(),\n",
    "    # Layer 4\n",
    "    Linear(NUM_HIDDEN_NEURONS, NUM_HIDDEN_NEURONS, bias=False),\n",
    "    BatchNorm1d(NUM_HIDDEN_NEURONS),\n",
    "    Tanh(),\n",
    "    # Layer 5\n",
    "    Linear(NUM_HIDDEN_NEURONS, NUM_HIDDEN_NEURONS, bias=False),\n",
    "    BatchNorm1d(NUM_HIDDEN_NEURONS),\n",
    "    Tanh(),\n",
    "    # Output layer\n",
    "    Linear(NUM_HIDDEN_NEURONS, VOCAB_SIZE, bias=False),\n",
    "    BatchNorm1d(VOCAB_SIZE),\n",
    "])\n",
    "with torch.no_grad():\n",
    "  # last layer: make less confident\n",
    "  model.layers[-1].gamma *= 0.1\n",
    "\n",
    "parameters = model.parameters()\n",
    "print(\"Total params: \", sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/  20000: 3.3360\n",
      "   1000/  20000: 2.6625\n",
      "   2000/  20000: 2.4376\n",
      "   3000/  20000: 2.3973\n",
      "   4000/  20000: 1.7952\n",
      "   5000/  20000: 2.4707\n",
      "   6000/  20000: 2.3159\n",
      "   7000/  20000: 2.1150\n",
      "   8000/  20000: 2.3277\n",
      "   9000/  20000: 2.4479\n",
      "  10000/  20000: 2.1508\n",
      "  11000/  20000: 2.4334\n",
      "  12000/  20000: 2.0012\n",
      "  13000/  20000: 1.9161\n",
      "  14000/  20000: 2.4280\n",
      "  15000/  20000: 2.0505\n",
      "  16000/  20000: 1.6496\n",
      "  17000/  20000: 2.2935\n",
      "  18000/  20000: 1.8684\n",
      "  19000/  20000: 2.4034\n",
      "2.049808979034424\n"
     ]
    }
   ],
   "source": [
    "max_steps = 20000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "ud = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    logits = model(Xb)\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for layer in layers:\n",
    "        layer.out.retain_grad() # AFTER_DEBUG: would take out retain_graph\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 15000 else 0.01 # step learning rate decay\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "\n",
    "    # track stats\n",
    "    if i % 1000 == 0: # print every once in a while\n",
    "        print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.item())\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.1319594383239746\n",
      "val 2.1536943912506104\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "    \"\"\"Simple function to take a split of the data and compute the loss.  No\n",
    "    gradients will be calculated.\"\"\"\n",
    "    x,y = {\n",
    "        'train': (Xtr,  Ytr),\n",
    "        'val'  : (Xdev, Ydev),\n",
    "        'test' : (Xte,  Yte),\n",
    "    }[split]\n",
    "    # forward pass\n",
    "    logits = model(x)\n",
    "    loss = F.cross_entropy(logits, y) # loss function\n",
    "    print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carmahfamille.\n",
      "khi.\n",
      "mili.\n",
      "taty.\n",
      "skanden.\n",
      "jazontefamerynci.\n",
      "aqui.\n",
      "nellara.\n",
      "chaiiv.\n",
      "kaleigh.\n",
      "ham.\n",
      "jock.\n",
      "quinton.\n",
      "lilea.\n",
      "jadiquinterridearynix.\n",
      "kael.\n",
      "dura.\n",
      "med.\n",
      "emiia.\n",
      "giley.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for layer in model.layers:\n",
    "   layer.training = False\n",
    "   \n",
    "\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * BLOCK_SIZE # initialize with all ...\n",
    "    while True:\n",
    "      # forward pass the neural net\n",
    "      logits = model(torch.tensor([context]))\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      # sample from the distribution\n",
    "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "      # shift the context window and track the samples\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      # if we sample the special '.' token, break\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out)) # decode and print the generated word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182580, 8]) torch.Size([182580])\n",
      "torch.Size([22767, 8]) torch.Size([22767])\n",
      "torch.Size([22799, 8]) torch.Size([22799])\n"
     ]
    }
   ],
   "source": [
    "# Let's start experimenting as we start to implement WaveNet.\n",
    "# https://arxiv.org/abs/1609.03499 \n",
    "\n",
    "BLOCK_SIZE = 8  # Context length.  How many letters do we take to predict the next.\n",
    "\n",
    "# Build a data set.\n",
    "def build_dataset(words): \n",
    "    \"\"\"Build a data set from the given data.\n",
    "  \n",
    "    Returns: \n",
    "      torch.tensor: X inputs (context block_size long)\n",
    "      torch.tensor: Y labels\n",
    "    \"\"\"\n",
    "    X, Y = [], []\n",
    "  \n",
    "    for w in words:\n",
    "        context = [0] * BLOCK_SIZE\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix] # crop and append\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "# Going to split the training set.\n",
    "n1 = int(0.8*len(words))  # 80% for training.\n",
    "n2 = int(0.9*len(words))  # 10% for dev, and then 10% for eval.\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params:  22124\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(42) # for reproducibility\n",
    "EMBED_SIZE = 10\n",
    "NUM_HIDDEN_NEURONS = 200\n",
    "L1_INPUT_SIZE = EMBED_SIZE * BLOCK_SIZE\n",
    "\n",
    "model = Sequential([\n",
    "    # Layer 0: Embeddings.\n",
    "    Embedding(VOCAB_SIZE, EMBED_SIZE),\n",
    "    # Layer 0b: Flatten to an input to the hidden layers.\n",
    "    Flatten(),\n",
    "    # Layer 1: Input from embeddings.\n",
    "    Linear(L1_INPUT_SIZE, NUM_HIDDEN_NEURONS, bias=False),\n",
    "    BatchNorm1d(NUM_HIDDEN_NEURONS),\n",
    "    Tanh(),\n",
    "    # Output layer\n",
    "    Linear(NUM_HIDDEN_NEURONS, VOCAB_SIZE, bias=False),\n",
    "    BatchNorm1d(VOCAB_SIZE),\n",
    "])\n",
    "with torch.no_grad():\n",
    "  # last layer: make less confident\n",
    "  model.layers[-1].gamma *= 0.1\n",
    "\n",
    "parameters = model.parameters()\n",
    "print(\"Total params: \", sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/  20000: 3.3130\n",
      "3.312997817993164\n"
     ]
    }
   ],
   "source": [
    "max_steps = 20000\n",
    "batch_size = 4\n",
    "lossi = []\n",
    "ud = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    logits = model(Xb)\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for layer in layers:\n",
    "        layer.out.retain_grad() # AFTER_DEBUG: would take out retain_graph\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 15000 else 0.01 # step learning rate decay\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "\n",
    "    # track stats\n",
    "    if i % 1000 == 0: # print every once in a while\n",
    "        print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.item())\n",
    "    break\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 10])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].out.shape  # output of embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 80])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].out.shape  # output of flatten layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 200])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[2].out.shape  # output of linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 200])\n",
      "torch.Size([4, 6, 200])\n"
     ]
    }
   ],
   "source": [
    "# Right now we're taking all 8 context chars and multiplying against the weights all at once.  \n",
    "# But in the WaveNet, they take pairs of chars to apply to weights.  torch allows us to break apart\n",
    "# leading dimensions.  It only cares about the final dimension for the multiply.  It treats all\n",
    "# of the leading dimensions as batches, or groups.\n",
    "print((torch.rand(4, 80) @ torch.randn(80, 200)).shape)\n",
    "print((torch.rand(4, 6, 80) @ torch.randn(80, 200)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4, 200])\n",
      "torch.Size([4, 80])\n",
      "[0, 2, 4, 6, 8]\n",
      "even:  torch.Size([4, 4, 10])\n",
      "odd :  torch.Size([4, 4, 10])\n",
      "cat try1:  torch.Size([8, 4, 10])\n",
      "cat try2:  torch.Size([4, 4, 20])\n"
     ]
    }
   ],
   "source": [
    "# Our input is:\n",
    "# 1 2 3 4 5 6 7 8\n",
    "# Want\n",
    "# (1 2) (3 4) (5 6) (7 8)\n",
    "# So instead of 80, we would expect 4 by 20\n",
    "print((torch.rand(4, 4, 20) @ torch.randn(20, 200)).shape)\n",
    "# So we need to change our Flatten layer.\n",
    "example = torch.randn(4, 8, 10)  # What we get from embedding\n",
    "print(example.view(example.shape[0], -1).shape)  # This is what flattening currently does.\n",
    "# We can index in the tensor by reading all of a dimension (:), every other (::2).\n",
    "print(list(range(10))[::2])  # Sample for every-other list.\n",
    "print(\"even: \", example[:, ::2, :].shape)\n",
    "# That indexing gave the proper shape as output.  We also need the odd-index version:\n",
    "print(\"odd : \", example[:, 1::2, :].shape)\n",
    "# cat them together:\n",
    "print(\"cat try1: \", torch.cat((example[:, ::2, :], example[:, 1::2, :])).shape)\n",
    "# That looks wrong, because it combined the first dimension, not the second one.\n",
    "print(\"cat try2: \", torch.cat((example[:, ::2, :], example[:, 1::2, :]), dim=2).shape)\n",
    "# Looks correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But torch can do this for us.  We can just tell view how we want to see it.\n",
    "explicit = torch.cat((example[:, ::2, :], example[:, 1::2, :]), dim=2)\n",
    "faster = example.view(4, 4, 20)\n",
    "(explicit == faster).all()  # They should match.\n",
    "# And they do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to make a new layer type to do this more interesting flatten step.\n",
    "\n",
    "class FlattenConsecutive:\n",
    "    def __init__(self, num_consecutive_elements):\n",
    "        self.n = num_consecutive_elements\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        \"\"\"Keep the first dimension, and adjust the other dimensions according to the\n",
    "        number of consecutive elements that should be grouped.\n",
    "\n",
    "        The second dimension should get reduced by the number of consecutive elements we\n",
    "        will group, and the last dimension will go up by that many elements.\n",
    "        \"\"\"\n",
    "        B, T, C = x.shape  # Batch, Tokens, Embedding vector (called Channels by torch)\n",
    "        x = x.view(B, T//self.n, C*self.n)\n",
    "        if x.shape[1] == 1:  # If the second dimension is just 1 element, get rid of it.\n",
    "            x = x.squeeze(1)\n",
    "        self.out = x\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params:  22370\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "EMBED_SIZE = 10\n",
    "GROUP_SIZE = 2\n",
    "NUM_HIDDEN_NEURONS = 68\n",
    "L1_INPUT_SIZE = EMBED_SIZE * GROUP_SIZE\n",
    "\n",
    "model = Sequential([\n",
    "    # Layer 0: Embeddings.\n",
    "    Embedding(VOCAB_SIZE, EMBED_SIZE),\n",
    "    \n",
    "    # Layer 1: Input from embeddings.\n",
    "    FlattenConsecutive(GROUP_SIZE),\n",
    "    Linear(L1_INPUT_SIZE, NUM_HIDDEN_NEURONS, bias=False),\n",
    "    BatchNorm1d(NUM_HIDDEN_NEURONS),\n",
    "    Tanh(),\n",
    "    \n",
    "    # Layer 2: Hidden layer.\n",
    "    FlattenConsecutive(GROUP_SIZE),\n",
    "    Linear(NUM_HIDDEN_NEURONS * GROUP_SIZE, NUM_HIDDEN_NEURONS, bias=False),\n",
    "    BatchNorm1d(NUM_HIDDEN_NEURONS),\n",
    "    Tanh(),\n",
    "    \n",
    "    # Layer 2: Hidden layer.\n",
    "    FlattenConsecutive(GROUP_SIZE),\n",
    "    Linear(NUM_HIDDEN_NEURONS * GROUP_SIZE, NUM_HIDDEN_NEURONS, bias=False),\n",
    "    BatchNorm1d(NUM_HIDDEN_NEURONS),\n",
    "    Tanh(),\n",
    "    \n",
    "    # Output layer\n",
    "    Linear(NUM_HIDDEN_NEURONS, VOCAB_SIZE, bias=False),\n",
    "])\n",
    "with torch.no_grad():\n",
    "    # last layer: make less confident\n",
    "    model.layers[-1].weight *= 0.1\n",
    "\n",
    "parameters = model.parameters()\n",
    "print(\"Total params: \", sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/  20000: 3.3062\n",
      "   1000/  20000: 2.3637\n",
      "   2000/  20000: 2.0799\n",
      "   3000/  20000: 2.4182\n",
      "   4000/  20000: 2.0593\n",
      "   5000/  20000: 2.2573\n",
      "   6000/  20000: 2.6915\n",
      "   7000/  20000: 2.6990\n",
      "   8000/  20000: 2.1639\n",
      "   9000/  20000: 1.8186\n",
      "  10000/  20000: 2.6122\n",
      "  11000/  20000: 2.0966\n",
      "  12000/  20000: 2.0769\n",
      "  13000/  20000: 2.3389\n",
      "  14000/  20000: 2.3431\n",
      "  15000/  20000: 2.4200\n",
      "  16000/  20000: 2.0399\n",
      "  17000/  20000: 2.0850\n",
      "  18000/  20000: 2.0851\n",
      "  19000/  20000: 2.0204\n",
      "2.1082584857940674\n"
     ]
    }
   ],
   "source": [
    "max_steps = 20000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "ud = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    logits = model(Xb)\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for layer in layers:\n",
    "        layer.out.retain_grad() # AFTER_DEBUG: would take out retain_graph\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 15000 else 0.01 # step learning rate decay\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "\n",
    "    # track stats\n",
    "    if i % 1000 == 0: # print every once in a while\n",
    "        print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.item())\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding : (32, 8, 10)\n",
      "FlattenConsecutive : (32, 4, 20)\n",
      "Linear : (32, 4, 68)\n",
      "BatchNorm1d : (32, 4, 68)\n",
      "Tanh : (32, 4, 68)\n",
      "FlattenConsecutive : (32, 2, 136)\n",
      "Linear : (32, 2, 68)\n",
      "BatchNorm1d : (32, 2, 68)\n",
      "Tanh : (32, 2, 68)\n",
      "FlattenConsecutive : (32, 136)\n",
      "Linear : (32, 68)\n",
      "BatchNorm1d : (32, 68)\n",
      "Tanh : (32, 68)\n",
      "Linear : (32, 27)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.__class__.__name__, \":\", tuple(layer.out.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 68])\n",
      "torch.Size([1, 1, 68])\n"
     ]
    }
   ],
   "source": [
    "# Let's debug the bachnorm layer a bit.\n",
    "\n",
    "examp = torch.randn(32, 4, 68)  # Our input shape.\n",
    "emean = examp.mean(0, keepdim=True)\n",
    "evar  = examp.var( 0, keepdim=True)\n",
    "ehat  = (examp - emean) / torch.sqrt(evar + 1e-5)\n",
    "print(ehat.shape)\n",
    "# Note that the shape has a middle dimension of 4.  So we are keeping 4 independant means and variences. \n",
    "# We don't want it spit up like this.  We want the mean and variance for all samples together.\n",
    "# We need to update the torch.mean and var calls.  They can take a tuple of dimensions to calculate over.\n",
    "emean = examp.mean((0, 1), keepdim=True)\n",
    "evar  = examp.var( (0, 1), keepdim=True)\n",
    "print(emean.shape)\n",
    "# Note this is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's rebuild the BatchNorm1d class to fix this issue.\n",
    "class BatchNorm1d:\n",
    "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.training = True\n",
    "        # parameters (trained with backprop)\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta  = torch.zeros(dim)\n",
    "        # buffers (trained with a running 'momentum update')\n",
    "        self.running_mean = torch.zeros(dim)\n",
    "        self.running_var = torch.ones(dim)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # calculate the forward pass\n",
    "        if self.training:\n",
    "            if x.ndim == 2:\n",
    "                dim = 0\n",
    "            elif x.ndim == 3:\n",
    "                dim = (0, 1)  # Average over multiple dimensions.\n",
    "            xmean = x.mean(dim, keepdim=True) # batch mean\n",
    "            xvar  = x.var( dim, keepdim=True) # batch variance\n",
    "        else:\n",
    "            xmean = self.running_mean\n",
    "            xvar = self.running_var\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "        # update the buffers\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
    "                self.running_var  = (1 - self.momentum) * self.running_var  + self.momentum * xvar\n",
    "        return self.out\n",
    "  \n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params:  22370\n"
     ]
    }
   ],
   "source": [
    "# Rebuild with our new type.\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "EMBED_SIZE = 10\n",
    "GROUP_SIZE = 2\n",
    "NUM_HIDDEN_NEURONS = 68\n",
    "L1_INPUT_SIZE = EMBED_SIZE * GROUP_SIZE\n",
    "\n",
    "model = Sequential([\n",
    "    # Layer 0: Embeddings.\n",
    "    Embedding(VOCAB_SIZE, EMBED_SIZE),\n",
    "    \n",
    "    # Layer 1: Input from embeddings.\n",
    "    FlattenConsecutive(GROUP_SIZE),\n",
    "    Linear(L1_INPUT_SIZE, NUM_HIDDEN_NEURONS, bias=False),\n",
    "    BatchNorm1d(NUM_HIDDEN_NEURONS),\n",
    "    Tanh(),\n",
    "    \n",
    "    # Layer 2: Hidden layer.\n",
    "    FlattenConsecutive(GROUP_SIZE),\n",
    "    Linear(NUM_HIDDEN_NEURONS * GROUP_SIZE, NUM_HIDDEN_NEURONS, bias=False),\n",
    "    BatchNorm1d(NUM_HIDDEN_NEURONS),\n",
    "    Tanh(),\n",
    "    \n",
    "    # Layer 2: Hidden layer.\n",
    "    FlattenConsecutive(GROUP_SIZE),\n",
    "    Linear(NUM_HIDDEN_NEURONS * GROUP_SIZE, NUM_HIDDEN_NEURONS, bias=False),\n",
    "    BatchNorm1d(NUM_HIDDEN_NEURONS),\n",
    "    Tanh(),\n",
    "    \n",
    "    # Output layer\n",
    "    Linear(NUM_HIDDEN_NEURONS, VOCAB_SIZE, bias=False),\n",
    "])\n",
    "with torch.no_grad():\n",
    "    # last layer: make less confident\n",
    "    model.layers[-1].weight *= 0.1\n",
    "\n",
    "parameters = model.parameters()\n",
    "print(\"Total params: \", sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/  20000: 3.2965\n",
      "   1000/  20000: 2.4132\n",
      "   2000/  20000: 1.9985\n",
      "   3000/  20000: 2.2158\n",
      "   4000/  20000: 2.0901\n",
      "   5000/  20000: 2.2129\n",
      "   6000/  20000: 2.6442\n",
      "   7000/  20000: 2.5397\n",
      "   8000/  20000: 1.9940\n",
      "   9000/  20000: 1.8370\n",
      "  10000/  20000: 2.4955\n",
      "  11000/  20000: 2.0929\n",
      "  12000/  20000: 2.2284\n",
      "  13000/  20000: 2.3509\n",
      "  14000/  20000: 2.2161\n",
      "  15000/  20000: 2.3734\n",
      "  16000/  20000: 2.0721\n",
      "  17000/  20000: 2.0861\n",
      "  18000/  20000: 2.0556\n",
      "  19000/  20000: 2.0253\n",
      "2.0163474082946777\n",
      "torch.Size([1, 1, 68])\n"
     ]
    }
   ],
   "source": [
    "max_steps = 20000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "ud = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    logits = model(Xb)\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for layer in layers:\n",
    "        layer.out.retain_grad() # AFTER_DEBUG: would take out retain_graph\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 15000 else 0.01 # step learning rate decay\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "\n",
    "    # track stats\n",
    "    if i % 1000 == 0: # print every once in a while\n",
    "        print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.item())\n",
    "\n",
    "print(loss.item())\n",
    "print(model.layers[3].running_mean.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43dd406cf07603aefb2bc1f435b01d13dd3834c8eeb71afea2303e52aded1d18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
